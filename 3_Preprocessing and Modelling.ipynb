{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oghenevwedeagboro-jimoh/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling Imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# NLP Imports\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>alltexts</th>\n",
       "      <th>alltexts_word_count</th>\n",
       "      <th>alltexts_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Score in S10E09</td>\n",
       "      <td>Anybody knows where to find the score of every...</td>\n",
       "      <td>1</td>\n",
       "      <td>Score in S10E09 Anybody knows where to find th...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amc early access</td>\n",
       "      <td>When does early access for the episode go live...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amc early access When does early access for th...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does TWD MTG cards logo features a shootin...</td>\n",
       "      <td>If you look at the new MTG TWD cards the logo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why does TWD MTG cards logo features a shootin...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is fear the walking dead worth watching?</td>\n",
       "      <td>I got into walking dead around 2012. All it to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is fear the walking dead worth watching? I got...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So idk if its just me hearing this but in S6 E...</td>\n",
       "      <td>lol</td>\n",
       "      <td>1</td>\n",
       "      <td>So idk if its just me hearing this but in S6 E...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                    Score in S10E09   \n",
       "1                                   Amc early access   \n",
       "2  Why does TWD MTG cards logo features a shootin...   \n",
       "3           Is fear the walking dead worth watching?   \n",
       "4  So idk if its just me hearing this but in S6 E...   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0  Anybody knows where to find the score of every...          1   \n",
       "1  When does early access for the episode go live...          1   \n",
       "2  If you look at the new MTG TWD cards the logo ...          1   \n",
       "3  I got into walking dead around 2012. All it to...          1   \n",
       "4                                                lol          1   \n",
       "\n",
       "                                            alltexts  alltexts_word_count  \\\n",
       "0  Score in S10E09 Anybody knows where to find th...                 25.0   \n",
       "1  Amc early access When does early access for th...                 24.0   \n",
       "2  Why does TWD MTG cards logo features a shootin...                133.0   \n",
       "3  Is fear the walking dead worth watching? I got...                 83.0   \n",
       "4  So idk if its just me hearing this but in S6 E...                 34.0   \n",
       "\n",
       "   alltexts_length  \n",
       "0            153.0  \n",
       "1            118.0  \n",
       "2            912.0  \n",
       "3            452.0  \n",
       "4            156.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2964, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2964 entries, 0 to 2963\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   title                2964 non-null   object \n",
      " 1   selftext             2964 non-null   object \n",
      " 2   subreddit            2964 non-null   int64  \n",
      " 3   alltexts             2964 non-null   object \n",
      " 4   alltexts_word_count  2964 non-null   float64\n",
      " 5   alltexts_length      2964 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 139.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, there are no missing values. So we will go ahead and set up X and y for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would be using the alltext since its a combination of the title and the selftext.\n",
    "X = df['alltexts']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2223,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2223,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function to calculate and display the classification metrics\n",
    "# Courtesy of Eboni Lee\n",
    "def class_metrics(model, X, y):\n",
    "    # Generate the prediction\n",
    "    preds = model.predict(X)\n",
    "    # Get the confusion matrix and ravel\n",
    "    tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n",
    "    # Accuracy\n",
    "    print(f' The Accuracy is :{round((tp + tn)/len(y), 3)}')\n",
    "    # Sensitivity\n",
    "    print(f' The Sensitivity is :{round(tp/(tp+fn), 3)}')\n",
    "    # Specificity\n",
    "    print(f' The Specificity is :{round(tn/(tn+fp), 3)}')\n",
    "    # Precision\n",
    "    print(f' The Precision is :{round(tp/(tp+fp), 3)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzers so that we can stick them in the pipelines\n",
    "# Courtesy of stackoverflow\n",
    "\n",
    "# PorterStemmer - CVEC\n",
    "stemmer = PorterStemmer()\n",
    "cvec_analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def porter_cvec_words(doc):\n",
    "    return (stemmer.stem(w) for w in cvec_analyzer(doc))\n",
    "\n",
    "# PorterStemmer - TFIDF\n",
    "tfidf_analyzer = TfidfVectorizer().build_analyzer()\n",
    "\n",
    "def porter_tfidf_words(doc):\n",
    "    return (stemmer.stem(w) for w in tfidf_analyzer(doc))\n",
    "\n",
    "# WordNetLemmatizer - CVEC\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "def lemm_cvec_words(doc):\n",
    "    return (lemm.lemmatize(w) for w in cvec_analyzer(doc))\n",
    "\n",
    "# WordNetLemmatizer - TFIDF\n",
    "def lemm_tfidf_words(doc):\n",
    "    return (lemm.lemmatize(w) for w in tfidf_analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor \n",
    "dr = DummyRegressor()\n",
    "dr.fit(X_test, y_test)\n",
    "dr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__analyzer': 'word', 'cvec__max_features': 500, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english', 'lr__C': 0.1, 'lr__penalty': 'l2'}\n",
      " The Accuracy is :0.942\n",
      " The Sensitivity is :0.967\n",
      " The Specificity is :0.915\n",
      " The Precision is :0.926\n"
     ]
    }
   ],
   "source": [
    "# Set up the pipeline\n",
    "c_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Pipe parameters\n",
    "c_pipe_params = {\n",
    "    'cvec__max_features': [100, 500],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'cvec__analyzer': ['word', porter_cvec_words, lemm_cvec_words],\n",
    "    'lr__C': [0.1, 1, 1e9],\n",
    "    'lr__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Instantiate a GridSearchCV\n",
    "c_gs = GridSearchCV(c_pipe,\n",
    "                   c_pipe_params,\n",
    "                   cv=5,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "# Fit\n",
    "c_gs.fit(X_train, y_train)\n",
    "\n",
    "# Show metrics and best parameters\n",
    "print(c_gs.best_params_)\n",
    "class_metrics(c_gs, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Accuracy is :0.975\n",
      " The Sensitivity is :0.991\n",
      " The Specificity is :0.956\n",
      " The Precision is :0.962\n"
     ]
    }
   ],
   "source": [
    "class_metrics(c_gs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results seem to be very good, the four classification metrics were all greater than 0.92 which is strong. The Sensitivity and Specificity are both similar so we are correctly classifying both subreddits at a similar accuracy. The difference in the training and testing score is 0.033, so there isn't significant overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'tfidf__max_features': 500, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None}\n",
      " The Accuracy is :0.946\n",
      " The Sensitivity is :0.949\n",
      " The Specificity is :0.943\n",
      " The Precision is :0.949\n"
     ]
    }
   ],
   "source": [
    "# Using the same steps as above\n",
    "lr_tf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer=porter_tfidf_words)),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Pipe parameters\n",
    "lr_tf_pipe_params = {\n",
    "    'tfidf__max_features':[100, 500],\n",
    "    'tfidf__stop_words':[None, 'english'],\n",
    "    'tfidf__ngram_range':[(1,1), (1,2)],\n",
    "    'lr__C':[0.1, 1, 1e9]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch for the tfidf\n",
    "lr_tf_gs = GridSearchCV(lr_tf_pipe,\n",
    "                        lr_tf_pipe_params,\n",
    "                        cv=5,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch\n",
    "lr_tf_gs.fit(X_train, y_train);\n",
    "\n",
    "# Display the metrics and best parameters\n",
    "print(lr_tf_gs.best_params_)\n",
    "class_metrics(lr_tf_gs, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class_metrics(lr_tf_gs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LogisticRegression using TfidfVectorizer gave very similar results with the CountVectorizer using same model. And just like the CountVectorizer it did overfit slightly. However the only similarities in the parameters were the ngram_range and the max_features which were (1,1) and 500 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Multinomial Naive Bayes with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__analyzer': 'word', 'cvec__max_features': 500, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english', 'mnb__alpha': 0.1}\n",
      " The Accuracy is :0.957\n",
      " The Sensitivity is :0.974\n",
      " The Specificity is :0.938\n",
      " The Precision is :0.945\n"
     ]
    }
   ],
   "source": [
    "# Set up the pipeline\n",
    "mc_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Pipe parameters\n",
    "mc_pipe_params = {\n",
    "    'cvec__max_features': [100, 500],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'cvec__analyzer': ['word', porter_cvec_words, lemm_cvec_words],\n",
    "    'mnb__alpha':[0.1, 0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Instantiate a GridSearchCV\n",
    "mc_gs = GridSearchCV(mc_pipe,\n",
    "                   mc_pipe_params,\n",
    "                   cv=5,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "# Fit\n",
    "mc_gs.fit(X_train, y_train)\n",
    "\n",
    "# Show metrics and best parameters\n",
    "print(mc_gs.best_params_)\n",
    "class_metrics(mc_gs, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Accuracy is :0.969\n",
      " The Sensitivity is :0.981\n",
      " The Specificity is :0.955\n",
      " The Precision is :0.96\n"
     ]
    }
   ],
   "source": [
    "class_metrics(mc_gs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Multinomial Bayes Model with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnb__alpha': 0.1, 'tfidf__max_features': 500, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None}\n",
      " The Accuracy is :0.962\n",
      " The Sensitivity is :0.974\n",
      " The Specificity is :0.949\n",
      " The Precision is :0.955\n"
     ]
    }
   ],
   "source": [
    "# Using the same steps as above\n",
    "mnb_tf_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(analyzer=porter_tfidf_words)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Pipe parameters\n",
    "mnb_tf_pipe_params = {\n",
    "    'tfidf__max_features':[100, 500],\n",
    "    'tfidf__stop_words':[None, 'english'],\n",
    "    'tfidf__ngram_range':[(1,1), (1,2)],\n",
    "    'mnb__alpha':[0.1, 0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch for the tfidf\n",
    "mnb_tf_gs = GridSearchCV(mnb_tf_pipe,\n",
    "                        mnb_tf_pipe_params,\n",
    "                        cv=5,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch\n",
    "mnb_tf_gs.fit(X_train, y_train);\n",
    "\n",
    "# Display the metrics and best parameters\n",
    "print(mnb_tf_gs.best_params_)\n",
    "class_metrics(mnb_tf_gs, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Accuracy is :0.97\n",
      " The Sensitivity is :0.981\n",
      " The Specificity is :0.958\n",
      " The Precision is :0.963\n"
     ]
    }
   ],
   "source": [
    "class_metrics(mnb_tf_gs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
